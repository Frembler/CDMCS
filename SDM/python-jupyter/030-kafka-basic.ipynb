{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka with python\n",
    "\n",
    "See:\n",
    "\n",
    "* https://kafka-python.readthedocs.io/en/master/apidoc/KafkaConsumer.html\n",
    "* https://kafka-python.readthedocs.io/en/master/apidoc/KafkaProducer.html\n",
    "\n",
    "> This example assumes SDM singlehost setup with docker-compose. Name resolution to kafka producers in handled by docker.\n",
    "\n",
    "Lets start by producing some simple messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"testing\"\n",
    "server = \"kafka:9092\"\n",
    "producer = KafkaProducer(bootstrap_servers=server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    msg = \"message %s\" % (i)\n",
    "    resp = producer.send(topic, bytes(msg, encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consume those messages. Note that we need to consume messages from beginning for this example to work.\n",
    "\n",
    "> Python kafka consumer may take some time to reconnect and start consuming if commits are enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConsumerRecord(topic='testing', partition=1, offset=0, timestamp=1519566433974, timestamp_type=0, key=None, value=b'message 0', checksum=1684907871, serialized_key_size=-1, serialized_value_size=9)\n",
      "ConsumerRecord(topic='testing', partition=1, offset=1, timestamp=1519566433974, timestamp_type=0, key=None, value=b'message 1', checksum=325752777, serialized_key_size=-1, serialized_value_size=9)\n",
      "ConsumerRecord(topic='testing', partition=1, offset=2, timestamp=1519566433974, timestamp_type=0, key=None, value=b'message 3', checksum=-43714843, serialized_key_size=-1, serialized_value_size=9)\n",
      "ConsumerRecord(topic='testing', partition=1, offset=3, timestamp=1519566433974, timestamp_type=0, key=None, value=b'message 4', checksum=1660969798, serialized_key_size=-1, serialized_value_size=9)\n",
      "ConsumerRecord(topic='testing', partition=1, offset=4, timestamp=1519566433975, timestamp_type=0, key=None, value=b'message 6', checksum=1650242699, serialized_key_size=-1, serialized_value_size=9)\n",
      "ConsumerRecord(topic='testing', partition=1, offset=5, timestamp=1519566433975, timestamp_type=0, key=None, value=b'message 8', checksum=-2048616052, serialized_key_size=-1, serialized_value_size=9)\n"
     ]
    }
   ],
   "source": [
    "consumer = KafkaConsumer(topic, group_id=None, bootstrap_servers=server, auto_offset_reset='earliest')\n",
    "\n",
    "i = 0\n",
    "for msg in consumer:\n",
    "    print(msg)\n",
    "    i += 1\n",
    "consumer.close(autocommit = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also access individual elements of a message, along with some meta information about the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing 0 0 message 2\n",
      "testing 0 1 message 2\n",
      "testing 0 2 message 1\n",
      "testing 0 3 message 0\n",
      "testing 0 4 message 5\n",
      "testing 0 5 message 6\n",
      "testing 0 6 message 1\n",
      "testing 0 7 message 2\n",
      "testing 0 8 message 5\n",
      "testing 0 9 message 7\n",
      "testing 0 10 message 9\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer, TopicPartition\n",
    "consumer = KafkaConsumer(topic, group_id=None, bootstrap_servers=server, auto_offset_reset='earliest')\n",
    "\n",
    "partitions = consumer.partitions_for_topic(topic)\n",
    "count_no_msgs_per_part = {}\n",
    "for part in partitions:\n",
    "    count_no_msgs_per_part[part] = 0\n",
    "    \n",
    "i = 0\n",
    "for msg in consumer:\n",
    "    count_no_msgs_per_part[msg.partition] += 1\n",
    "    print(msg.topic, msg.partition, msg.offset, str(msg.value, encoding = \"utf-8\"))\n",
    "    if i == 10:\n",
    "        break\n",
    "    i += 1\n",
    "#print(count_no_msgs_per_part)\n",
    "consumer.close(autocommit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
