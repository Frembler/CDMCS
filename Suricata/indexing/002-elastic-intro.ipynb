{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Elastic\n",
    "\n",
    "Start by importing elasticsearch library. Make sure it is installed with `python3 -m pip install --user elasticsearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish a connection. It will default to `localhost:9200` if `hosts` argument is omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(hosts=[\"localhost:9200\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always make sure your cluster connection is actually alive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index a first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'second',\n",
       " '_type': 'doc',\n",
       " '_id': 'BBBB',\n",
       " '_version': 16,\n",
       " 'result': 'updated',\n",
       " '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       " '_seq_no': 16,\n",
       " '_primary_term': 1}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = {\n",
    "    \"field1\": \"val1\",\n",
    "    \"field2\": \"val1\",\n",
    "    \"field3\": 123\n",
    "}\n",
    "es.index(\"second\", doc_type=\"doc\", body=document, id=\"BBBB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that elasticsearch library is just a wrapper for talking to HTTP API, so prior example is roughly equal to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'second', '_type': 'doc', '_id': 'BBBB', '_version': 17, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 17, '_primary_term': 1}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "url = \"http://localhost:9200/second/doc/BBBB\"\n",
    "headers = { \"Content-Type\": \"application/json\" }\n",
    "\n",
    "resp = requests.post(url, data=json.dumps(document), headers=headers)\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then retreive it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'second', '_type': 'doc', '_id': 'BBBB', '_version': 17, 'found': True, '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}}\n"
     ]
    }
   ],
   "source": [
    "newdoc = es.get(\"second\", doc_type=\"doc\", id=\"BBBB\")\n",
    "print(newdoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic attaches fair amount of meta information. Actual souce document is in `_source` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'field1': 'val1', 'field2': 'val1', 'field3': 123}\n"
     ]
    }
   ],
   "source": [
    "newdoc = newdoc[\"_source\"]\n",
    "print(newdoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elasticsearch uses HTTP and transport protocol, so indexing individual documents is fairly expensive. Especially when talking about IDS logs. Proper way is to use `bulk` API.\n",
    "\n",
    "See:\n",
    " * https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html\n",
    "\n",
    "Bulk format requires metadata line before each document to indicate what action should be taken, which index used, etc. Consider the illustration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {\n",
    "    \"index\": {\n",
    "        \"_index\": \"third\",\n",
    "        \"_type\": \"_doc\",\n",
    "        \"_id\": \"CCCC\"\n",
    "    }\n",
    "}\n",
    "\n",
    "bulk = []\n",
    "i = 0\n",
    "for i in range(100):\n",
    "    meta = {\n",
    "        \"index\": {\n",
    "            \"_index\": \"third\",\n",
    "            \"_type\": \"_doc\",\n",
    "            \"_id\": i\n",
    "        }\n",
    "    }\n",
    "    doc = {\n",
    "        \"message\": \"this is message {}\".format(i),\n",
    "        \"count\": i\n",
    "    }\n",
    "    \n",
    "    bulk.append(meta)\n",
    "    bulk.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': {'_index': 'third', '_type': '_doc', '_id': 0}}\n",
      "{'message': 'this is message 0', 'count': 0}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': 1}}\n",
      "{'message': 'this is message 1', 'count': 1}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': 2}}\n",
      "{'message': 'this is message 2', 'count': 2}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': 3}}\n",
      "{'message': 'this is message 3', 'count': 3}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': 4}}\n",
      "{'message': 'this is message 4', 'count': 4}\n"
     ]
    }
   ],
   "source": [
    "for msg in bulk[0:10]:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = es.bulk(bulk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['took', 'errors', 'items'])\n"
     ]
    }
   ],
   "source": [
    "print(resp.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(resp[\"errors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '0', '_version': 5, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 84, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '1', '_version': 5, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 72, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '2', '_version': 5, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 68, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '3', '_version': 5, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 92, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '4', '_version': 5, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 69, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '5', '_version': 5, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 84, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '6', '_version': 5, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 70, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '7', '_version': 5, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 73, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '8', '_version': 5, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 85, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '9', '_version': 5, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 86, '_primary_term': 1, 'status': 200}}\n"
     ]
    }
   ],
   "source": [
    "for result in resp[\"items\"][0:10]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run a search against this index, looking for documents where `count` field is `>= 12` or `<= 20`. Only three results are reported back to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['took', 'timed_out', '_shards', 'hits'])\n",
      "dict_keys(['total', 'max_score', 'hits'])\n"
     ]
    }
   ],
   "source": [
    "results = es.search(\"third\", body={\n",
    "    \"size\": 3,\n",
    "    \"query\": {\n",
    "        \"range\": {\n",
    "            \"count\": {\n",
    "                \"gte\": 12,\n",
    "                \"lte\": 20,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})\n",
    "print(results.keys())\n",
    "print(results[\"hits\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'third', '_type': '_doc', '_id': '14', '_score': 1.0, '_source': {'message': 'this is message 14', 'count': 14}}\n",
      "{'_index': 'third', '_type': '_doc', '_id': '19', '_score': 1.0, '_source': {'message': 'this is message 19', 'count': 19}}\n",
      "{'_index': 'third', '_type': '_doc', '_id': '12', '_score': 1.0, '_source': {'message': 'this is message 12', 'count': 12}}\n"
     ]
    }
   ],
   "source": [
    "if not results[\"timed_out\"]:\n",
    "    for result in results[\"hits\"][\"hits\"]:\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that omitting `_id` will cause elastic to autogenerate one. However, if you index the same log again, then having a distinct ID will cause the old one to be updated. Otherwise, the second indexing round will duplicate the log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'fourth',\n",
       " '_type': 'doc',\n",
       " '_id': 'BBBB',\n",
       " '_version': 8,\n",
       " 'result': 'updated',\n",
       " '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       " '_seq_no': 7,\n",
       " '_primary_term': 1}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.index(\"fourth\", doc_type=\"doc\", body=document, id=\"BBBB\")\n",
    "es.index(\"fourth\", doc_type=\"doc\", body=document, id=\"BBBB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'fifth',\n",
       " '_type': 'doc',\n",
       " '_id': 'O-f3dWgB6y6dRW9rRBkm',\n",
       " '_version': 1,\n",
       " 'result': 'created',\n",
       " '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       " '_seq_no': 3,\n",
       " '_primary_term': 1}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.index(\"fifth\", doc_type=\"doc\", body=document)\n",
    "es.index(\"fifth\", doc_type=\"doc\", body=document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = es.cat.indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow open second Auogp1nfRAyqQHYYS9CiAg 5 1   2 0  9.3kb  9.3kb\n",
      "yellow open fifth  jIYL8jZFRmGnvNXUBroZLw 5 1   8 0 21.4kb 21.4kb\n",
      "green  open first  dKmyapUCTSWaGunmnybU9A 5 0   2 0 31.5kb 31.5kb\n",
      "yellow open fourth jhY3bWMkR862MlqoZNwXrw 5 1   1 0  9.1kb  9.1kb\n",
      "yellow open third  osXNyLiETa--XFGTnQjySw 5 1 100 0 49.1kb 49.1kb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `fourth` has only one document while `fifth` has more (depending on how many times you executed this script). Yet, they are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 2,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 5, 'successful': 5, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': 8,\n",
       "  'max_score': 1.0,\n",
       "  'hits': [{'_index': 'fifth',\n",
       "    '_type': 'doc',\n",
       "    '_id': 'NufbdWgB6y6dRW9raxlg',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}},\n",
       "   {'_index': 'fifth',\n",
       "    '_type': 'doc',\n",
       "    '_id': 'N-fbdWgB6y6dRW9raxl8',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}},\n",
       "   {'_index': 'fifth',\n",
       "    '_type': 'doc',\n",
       "    '_id': 'OefgdWgB6y6dRW9rARkX',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}},\n",
       "   {'_index': 'fifth',\n",
       "    '_type': 'doc',\n",
       "    '_id': 'OOfgdWgB6y6dRW9rABn8',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}},\n",
       "   {'_index': 'fifth',\n",
       "    '_type': 'doc',\n",
       "    '_id': 'NOfRdWgB6y6dRW9rnhki',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}},\n",
       "   {'_index': 'fifth',\n",
       "    '_type': 'doc',\n",
       "    '_id': 'NefRdWgB6y6dRW9rnhlF',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}},\n",
       "   {'_index': 'fifth',\n",
       "    '_type': 'doc',\n",
       "    '_id': 'Ouf3dWgB6y6dRW9rRBkF',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}},\n",
       "   {'_index': 'fifth',\n",
       "    '_type': 'doc',\n",
       "    '_id': 'O-f3dWgB6y6dRW9rRBkm',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}}]}}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.search(\"fifth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 2,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 5, 'successful': 5, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': 1,\n",
       "  'max_score': 1.0,\n",
       "  'hits': [{'_index': 'fourth',\n",
       "    '_type': 'doc',\n",
       "    '_id': 'BBBB',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}}]}}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.search(\"fourth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, note that we can manage pretty much anything via elastic python API. For example, we could create mapping template programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {\n",
    "    \"index\": {\n",
    "        \"number_of_shards\": 3,\n",
    "        \"number_of_replicas\": 0,\n",
    "        \"refresh_interval\": \"30s\"\n",
    "    }\n",
    "}\n",
    "\n",
    "DEFAULT_PROPERTIES = {\n",
    "    \"@timestamp\": {\n",
    "        \"type\": \"date\",\n",
    "        \"format\": \"strict_date_optional_time||epoch_millis||date_time\"\n",
    "    },\n",
    "    \"@version\": {\n",
    "        \"type\": \"keyword\"\n",
    "    },\n",
    "    \"ip\": {\n",
    "        \"type\": \"ip\"\n",
    "    }\n",
    "}\n",
    "\n",
    "DEFAULT_MAPPINGS = {\n",
    "    \"_default_\": {\n",
    "        \"dynamic_templates\": [\n",
    "            {\n",
    "                \"message_field\": {\n",
    "                    \"path_match\": \"message\",\n",
    "                    \"mapping\": {\n",
    "                        \"norms\": False,\n",
    "                        \"type\": \"text\"\n",
    "                    },\n",
    "                    \"match_mapping_type\": \"string\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"string_fields\": {\n",
    "                    \"mapping\": {\n",
    "                        \"norms\": False,\n",
    "                        \"type\": \"text\",\n",
    "                        \"fields\": {\n",
    "                            \"keyword\": {\n",
    "                                \"type\": \"keyword\"\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"match_mapping_type\": \"string\",\n",
    "                    \"match\": \"*\"\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"properties\": DEFAULT_PROPERTIES\n",
    "    }\n",
    "}\n",
    "\n",
    "DEFAULT_TEMPLATE = {\n",
    "    \"order\": 0,\n",
    "    \"version\": 0,\n",
    "    \"index_patterns\": [\"logstash-*\"],\n",
    "    \"settings\": DEFAULT_SETTINGS,\n",
    "    \"mappings\": DEFAULT_MAPPINGS,\n",
    "    \"aliases\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'order': 0, 'version': 0, 'index_patterns': ['logstash-*'], 'settings': {'index': {'number_of_shards': 3, 'number_of_replicas': 0, 'refresh_interval': '30s'}}, 'mappings': {'_default_': {'dynamic_templates': [{'message_field': {'path_match': 'message', 'mapping': {'norms': False, 'type': 'text'}, 'match_mapping_type': 'string'}}, {'string_fields': {'mapping': {'norms': False, 'type': 'text', 'fields': {'keyword': {'type': 'keyword'}}}, 'match_mapping_type': 'string', 'match': '*'}}], 'properties': {'@timestamp': {'type': 'date', 'format': 'strict_date_optional_time||epoch_millis||date_time'}, '@version': {'type': 'keyword'}, 'ip': {'type': 'ip'}}}}, 'aliases': {}}\n"
     ]
    }
   ],
   "source": [
    "print(DEFAULT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "tpl = DEFAULT_TEMPLATE\n",
    "resp = es.indices.put_template(\"logstash\", body=tpl)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logstash': {'order': 0, 'version': 0, 'index_patterns': ['logstash-*'], 'settings': {'index': {'number_of_shards': '3', 'number_of_replicas': '0', 'refresh_interval': '30s'}}, 'mappings': {'_default_': {'dynamic_templates': [{'message_field': {'path_match': 'message', 'mapping': {'norms': False, 'type': 'text'}, 'match_mapping_type': 'string'}}, {'string_fields': {'mapping': {'norms': False, 'type': 'text', 'fields': {'keyword': {'type': 'keyword'}}}, 'match_mapping_type': 'string', 'match': '*'}}], 'properties': {'@timestamp': {'type': 'date', 'format': 'strict_date_optional_time||epoch_millis||date_time'}, '@version': {'type': 'keyword'}, 'ip': {'type': 'ip'}}}}, 'aliases': {}}}\n"
     ]
    }
   ],
   "source": [
    "resp = es.indices.get_template(\"logstash\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    " * Use elasticsearch `_bulk` API to index entire `eve.json` to index `suricata`\n",
    " * Loading entire file into memory and sending one huge bulk may be fine in class, but is a very bad idea in production;\n",
    "   * Choose an arbitrary bulk size N and flush logs to elastic when buffer is full;\n",
    "   * Don't forget the tail;\n",
    " * Index EVE logs dynamically based on `event_type` field;\n",
    "   * `alert` should be sent to index `suricata-alert` while `stats` should be sent to `suricata-stats`, etc;\n",
    " * Using information from EVE `timestamp` field, set up hourly index pattern;\n",
    "   * Final index pattern should look like `suricata-<event_type>-<YEAR>.<MONTH>.<DAY>.<HOUR>`\n",
    "   * For example, `suricata-alert-2019.01.22.16`\n",
    "   * Verify by writing a wildcard query for pattern `suricata-dns-2019.*`\n",
    " * Set up indexing template that matches all `suricata` prefixed indices;\n",
    "   * Disable replicas;\n",
    "   * Use non-deafault number of shards;\n",
    "   * Set `refresh_interval` to 3 seconds;\n",
    "   * Verify by deleting all suricata indices and reindexing using your scripts, use `_cat/indices` and `cat/_shards` api to validate;\n",
    " * Everyone usually uses logstash to do this stuff, some tools assume this and look for logstash-specific fields when running queries;\n",
    "   * Fix one future issue by adding a new field `@timestamp` to each document. It should correspond to `timestamp` field from EVE log;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
